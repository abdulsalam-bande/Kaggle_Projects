{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import utils\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "#Custom weight init\n",
    "def initi(m):\n",
    "    if isinstance(m,nn.Linear):\n",
    "        nn.init.xavier_uniform(m.weight.data)\n",
    "        \n",
    "\n",
    "#Simple json load\n",
    "with open(\"/Users/abdulsalamyazid/Desktop/Projects/Untitled Folder/train.json\") as f:\n",
    "    train = json.load(f)\n",
    "        \n",
    "with open(\"/Users/abdulsalamyazid/Desktop/Projects/Untitled Folder/test.json\") as f:\n",
    "    test = json.load(f)\n",
    "    \n",
    "print ('imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "xx=[d['ingredients'] for d in train]\n",
    "yy=[d['cuisine'] for d in train]\n",
    "word_list=set()\n",
    "for x in xx:\n",
    "    word_list|=set(tuple(x))\n",
    "word_list=list(word_list)\n",
    "#Make the list of cuisines \n",
    "\n",
    "cat_list=list(set(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list=set()\n",
    "for x in xx:\n",
    "    word_list|=set(tuple(x))\n",
    "word_list=list(word_list)\n",
    "#Make the list of cuisines \n",
    "\n",
    "cat_list=list(set(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 recepies of one hot vectors\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "First 5 cuisines in numerical\n",
      "[ 0 10 17 14 14]\n"
     ]
    }
   ],
   "source": [
    "newx=[]\n",
    "for num,rec in enumerate(xx):\n",
    "    newx.append(np.zeros(len(word_list)))\n",
    "    for ing in rec:\n",
    "        if ing in word_list:\n",
    "            ing_location=word_list.index(ing)\n",
    "            #newx[num][ing_location]=1/(ing_recep_count[ing_location])\n",
    "            newx[num][ing_location]=1\n",
    "newx=np.array(newx)\n",
    "\n",
    "\n",
    "#Convert the cuisines to numerical representation\n",
    "newy2=[]\n",
    "for num,rec in enumerate(yy):\n",
    "    newy2.append(cat_list.index(rec))\n",
    "newy2=np.array(newy2)\n",
    "\n",
    "print ('First 3 recepies of one hot vectors')\n",
    "print (newx[0:5])\n",
    "\n",
    "print ('First 5 cuisines in numerical')\n",
    "print (newy2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([31820, 6714])\n",
      "31820\n",
      "tensor(17)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SPLIT = 0.8\n",
    "#Splitting into training and validation sets with SPLIT amount\n",
    "tv=int(np.ceil(len(newx)*SPLIT))\n",
    "xtrain=newx[0:tv]\n",
    "ytrain=newy2[0:tv]\n",
    "xval=newx[tv:]\n",
    "yval=newy2[tv:]\n",
    "\n",
    "'''\n",
    "xtrain=newx\n",
    "ytrain=newy2\n",
    "'''\n",
    "print(type(xtrain))\n",
    "\n",
    "#Convert to tensors and variables\n",
    "txval= torch.from_numpy(xval)\n",
    "tyval=torch.from_numpy(yval)\n",
    "tx= torch.from_numpy(xtrain)\n",
    "ty=torch.from_numpy(ytrain)\n",
    "#tx=Variable(loader_train.__iter__().next()[0]).type(dtype)\n",
    "#tx=tx.cuda()\n",
    "print (tx.size())\n",
    "print(len(xtrain))\n",
    "print(ty[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31820, 6714)\n",
      "31820\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Training_DataSet(Dataset):\n",
    "    def __init__(self,X,Y,root_dir):\n",
    "        self.data_features = X\n",
    "        self.data_target = Y\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 31820\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        features = self.data_features[idx]  \n",
    "        target = self.data_target[idx]\n",
    "        \n",
    "\n",
    "        \n",
    "        sample = {\"features\":features,\"target\":target}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = Training_DataSet(xtrain,\n",
    "                                       ytrain,\n",
    "                                       root_dir=\"/Users/abdulsalamyazid/Desktop/Projects/Kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 0. 0. ... 0. 0. 0.] 0\n",
      "1 [0. 0. 0. ... 0. 0. 0.] 10\n",
      "2 [0. 0. 0. ... 0. 0. 0.] 17\n",
      "3 [0. 0. 0. ... 0. 0. 0.] 14\n",
      "4 [0. 0. 0. ... 0. 0. 0.] 14\n",
      "5 [0. 0. 0. ... 0. 0. 0.] 6\n",
      "6 [0. 0. 0. ... 0. 0. 0.] 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "   # print(i, sample['features'].,sample['target'].size())\n",
    "    print(i, sample['features'],sample['target'])\n",
    "\n",
    "    if i == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
