{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "sc_X = StandardScaler()\n",
    "Y = data[\"target\"]\n",
    "del data['target']\n",
    "del data['id']\n",
    "X = data\n",
    "X =  pd.DataFrame(sc_X.fit_transform(X))\n",
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()\n",
    "Y = np.array([Y])\n",
    "Y = Y.reshape((250,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Training_DataSet(Dataset):\n",
    "    def __init__(self,csv_file,X,Y,transform):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        features = self.X[idx]  \n",
    "        target = self.Y[idx]\n",
    "        \n",
    "        sample = {\"features\":features,\"target\":target}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class to_tensor_training(object):\n",
    "    def __call__(self,sample):\n",
    "        features , target = sample['features'],sample['target']\n",
    "        features = np.array([features])\n",
    "        features = features.astype('float32')\n",
    "        features = torch.from_numpy(features)\n",
    "        features = features.float()\n",
    "        target = np.array([target])\n",
    "        target = torch.from_numpy(target)\n",
    "        target = target.long()\n",
    "        \n",
    "        return {\"features\":features,\"target\":target}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = Training_DataSet(csv_file=\"train.csv\",\n",
    "                                       X = X,\n",
    "                                       Y = Y,\n",
    "                                       transform = to_tensor_training())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 300]) tensor([[1]])\n",
      "1 torch.Size([1, 300]) tensor([[0]])\n",
      "2 torch.Size([1, 300]) tensor([[1]])\n",
      "3 torch.Size([1, 300]) tensor([[1]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "    print(i, sample['features'].size(),sample['target'])\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(300,512)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(transformed_dataset,batch_size=4, shuffle=True,num_workers=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/ 10..  Training Loss: 0.662.. \n",
      "Accuracy  62 %\n",
      "Epoch: 2/ 10..  Training Loss: 0.514.. \n",
      "Accuracy  76 %\n",
      "Epoch: 3/ 10..  Training Loss: 0.392.. \n",
      "Accuracy  86 %\n",
      "Epoch: 4/ 10..  Training Loss: 0.284.. \n",
      "Accuracy  96 %\n",
      "Epoch: 5/ 10..  Training Loss: 0.204.. \n",
      "Accuracy  100 %\n",
      "Epoch: 6/ 10..  Training Loss: 0.148.. \n",
      "Accuracy  100 %\n",
      "Epoch: 7/ 10..  Training Loss: 0.109.. \n",
      "Accuracy  100 %\n",
      "Epoch: 8/ 10..  Training Loss: 0.082.. \n",
      "Accuracy  100 %\n",
      "Epoch: 9/ 10..  Training Loss: 0.065.. \n",
      "Accuracy  100 %\n",
      "Epoch: 10/ 10..  Training Loss: 0.052.. \n",
      "Accuracy  100 %\n",
      "Epoch: 11/ 10..  Training Loss: 0.043.. \n",
      "Accuracy  100 %\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "loss_array = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "accuracy_array = []\n",
    "for epoch in range(11):\n",
    "    running_loss = 0\n",
    "    for i , data in enumerate(trainloader,0):\n",
    "        features , target = data['features'],data['target']\n",
    "        target = target.squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(features)\n",
    "        outputs = outputs.squeeze()\n",
    "        _, predictions = torch.max(outputs,1)\n",
    "        total += target.size(0)\n",
    "        correct += (predictions == target).sum().item()\n",
    "        loss = criterion(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    loss_array.append(running_loss / len(trainloader))\n",
    "    \n",
    "    print(\"Epoch: {}/ 10.. \".format(epoch+1),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)))\n",
    "    print(\"Accuracy  %d %%\" %(100*correct/total))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
